"""
Google Gemini APIë¥¼ ì‚¬ìš©í•œ ë¸”ë¡œê·¸ ê¸€ ìƒì„± ëª¨ë“ˆ
"""
import json
import re
import sys
import os
import hashlib
from datetime import datetime
from pathlib import Path

import google.generativeai as genai

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.settings import GEMINI_API_KEY
from src.templates.prompts import (
    INFO_ARTICLE_PROMPT,
    EXPERIENCE_ARTICLE_PROMPT,
    TOPIC_SUGGESTION_PROMPT,
    QUESTION_BASED_ARTICLE_PROMPT,
    UNIFIED_ARTICLE_PROMPT,
)


class ContentGenerator:
    """Gemini ê¸°ë°˜ ì½˜í…ì¸  ìƒì„±ê¸°"""

    # ìºì‹œ ë””ë ‰í† ë¦¬
    CACHE_DIR = Path(__file__).parent.parent / "data" / "cache"

    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel(
            "gemini-2.5-flash",
            generation_config={
                "response_mime_type": "application/json",
                "max_output_tokens": 8192,
            }
        )
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.CACHE_DIR.mkdir(parents=True, exist_ok=True)

    def _get_cache_key(self, news_titles: list, category: str) -> str:
        """ë‰´ìŠ¤ ì œëª© ê¸°ë°˜ ìºì‹œ í‚¤ ìƒì„± (ë‹¹ì¼ ê¸°ì¤€)"""
        today = datetime.now().strftime("%Y%m%d")
        titles_str = "|".join(sorted([t["title"] for t in news_titles[:10]]))
        content = f"{today}:{category}:{titles_str}"
        return hashlib.md5(content.encode()).hexdigest()[:12]

    def _get_cached_article(self, cache_key: str) -> dict | None:
        """ìºì‹œëœ ê¸€ ê°€ì ¸ì˜¤ê¸°"""
        cache_file = self.CACHE_DIR / f"{cache_key}.json"
        if cache_file.exists():
            with open(cache_file, "r", encoding="utf-8") as f:
                cached = json.load(f)
                # ë‹¹ì¼ ìºì‹œë§Œ ìœ íš¨
                if cached.get("cached_date") == datetime.now().strftime("%Y%m%d"):
                    print("ğŸ“¦ ìºì‹œëœ ê¸€ ì‚¬ìš©")
                    return cached.get("article")
        return None

    def _save_to_cache(self, cache_key: str, article: dict):
        """ê¸€ ìºì‹œì— ì €ì¥"""
        cache_file = self.CACHE_DIR / f"{cache_key}.json"
        cache_data = {
            "cached_date": datetime.now().strftime("%Y%m%d"),
            "cached_at": datetime.now().isoformat(),
            "article": article,
        }
        with open(cache_file, "w", encoding="utf-8") as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)

    def _parse_json_response(self, text: str) -> dict:
        """ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
        original_text = text  # ë””ë²„ê¹…ìš© ì›ë³¸ ì €ì¥

        # JSON ë¸”ë¡ ì°¾ê¸°
        json_match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
        if json_match:
            text = json_match.group(1)

        # ì¤‘ê´„í˜¸ë¡œ ì‹œì‘í•˜ëŠ” JSON ì°¾ê¸°
        json_match = re.search(r"\{.*\}", text, re.DOTALL)
        if json_match:
            text = json_match.group(0)

        # ì²« ë²ˆì§¸ ì‹œë„: ê·¸ëŒ€ë¡œ íŒŒì‹±
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass

        # ë‘ ë²ˆì§¸ ì‹œë„: content í•„ë“œ ë‚´ ë¬¸ì œê°€ ìˆëŠ” ë¬¸ì ìˆ˜ì •
        try:
            # JSON ë¬¸ìì—´ ë‚´ë¶€ì˜ ì´ìŠ¤ì¼€ì´í”„ ì•ˆ ëœ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            fixed_text = re.sub(r'(?<!\\)\n', '\\n', text)
            # ì´ìŠ¤ì¼€ì´í”„ ì•ˆ ëœ íƒ­ ì²˜ë¦¬
            fixed_text = re.sub(r'(?<!\\)\t', '\\t', fixed_text)
            return json.loads(fixed_text)
        except json.JSONDecodeError:
            pass

        # ì„¸ ë²ˆì§¸ ì‹œë„: í•„ë“œë³„ë¡œ ì¶”ì¶œí•´ì„œ ì¬êµ¬ì„±
        try:
            result = {}

            # ê¸°ë³¸ ë¬¸ìì—´ í•„ë“œë“¤ ì¶”ì¶œ
            string_fields = [
                "trend_summary", "reader_perspective", "selected_topic",
                "title", "meta_description", "category"
            ]
            for field in string_fields:
                match = re.search(rf'"{field}"\s*:\s*"([^"]*)"', text)
                if match:
                    result[field] = match.group(1)

            # content í•„ë“œ (HTML í¬í•¨, ë³µì¡í•¨) - tags ì•ê¹Œì§€ ì¶”ì¶œ
            content_match = re.search(r'"content"\s*:\s*"(.*?)",\s*"tags"', text, re.DOTALL)
            if content_match:
                content = content_match.group(1)
                # ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                content = content.replace('\n', '').replace('\r', '')
                result["content"] = content

            # tags ë°°ì—´ ì¶”ì¶œ
            tags_match = re.search(r'"tags"\s*:\s*\[(.*?)\]', text, re.DOTALL)
            if tags_match:
                tags_str = tags_match.group(1)
                tags = [t.strip().strip('"').strip("'") for t in tags_str.split(',') if t.strip()]
                result["tags"] = tags

            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if result.get("title") and result.get("content"):
                return result

        except Exception as e:
            print(f"í•„ë“œë³„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        # ë„¤ ë²ˆì§¸ ì‹œë„: content í•„ë“œ ë‚´ ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ í•´ê²°
        try:
            # content ë‚´ë¶€ì˜ ì´ìŠ¤ì¼€ì´í”„ ì•ˆ ëœ ë”°ì˜´í‘œ ì²˜ë¦¬
            fixed_text = re.sub(r'(?<!\\)"(?=[^:,\[\]{}]*[,\]\}])', '\\"', text)
            return json.loads(fixed_text)
        except json.JSONDecodeError:
            pass

        raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨\nì›ë³¸: {original_text[:1000]}")

    def generate_info_article(self, news_data: dict) -> dict:
        """ì •ë³´í˜• ê¸€ ìƒì„±"""
        related = "\n".join(
            [f"  - {a['title']} ({a['source']})" for a in news_data.get("related_articles", [])]
        )

        prompt = INFO_ARTICLE_PROMPT.format(
            category_name=news_data["category_name"],
            main_title=news_data["main_article"]["title"],
            main_link=news_data["main_article"]["link"],
            source=news_data["main_article"]["source"],
            related_articles=related or "ì—†ìŒ",
        )

        response = self.model.generate_content(prompt)
        article = self._parse_json_response(response.text)

        article["article_type"] = "info"
        article["source_news"] = news_data["main_article"]["title"]

        return article

    def generate_experience_article(self, user_memo: str, category: str = "ì¼ìƒ/ë¦¬ë·°") -> dict:
        """ì²´í—˜í˜• ê¸€ ìƒì„±"""
        prompt = EXPERIENCE_ARTICLE_PROMPT.format(
            user_memo=user_memo,
            category=category,
        )

        response = self.model.generate_content(prompt)
        article = self._parse_json_response(response.text)

        article["article_type"] = "experience"
        article["user_memo"] = user_memo

        return article

    # ============================================================
    # ì§ˆë¬¸í˜• ì½˜í…ì¸  ìƒì„± (2ë‹¨ê³„)
    # ============================================================

    def suggest_topics(self, news_titles: list[dict]) -> dict:
        """Step 1: ë‰´ìŠ¤ ì œëª© ê¸°ë°˜ ë¸”ë¡œê·¸ ì£¼ì œ 3ê°œ ì œì•ˆ

        Args:
            news_titles: [{"title": "...", "source": "...", "lang": "..."}]

        Returns:
            {
                "trend_summary": "í•µì‹¬ íë¦„ ìš”ì•½",
                "reader_perspective": "ë…ì ê´€ì  ì¬í•´ì„",
                "suggested_topics": [{"topic": "...", "target": "...", "reason": "..."}]
            }
        """
        # ë‰´ìŠ¤ ì œëª©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        titles_str = "\n".join([f"- {item['title']}" for item in news_titles])

        prompt = TOPIC_SUGGESTION_PROMPT.format(news_titles=titles_str)

        response = self.model.generate_content(prompt)
        result = self._parse_json_response(response.text)

        return result

    def generate_question_based_article(
        self,
        selected_topic: str,
        trend_summary: str,
        category_name: str = "AI/í…Œí¬"
    ) -> dict:
        """Step 2: ì„ íƒëœ ì£¼ì œë¡œ ì§ˆë¬¸í˜• ë¸”ë¡œê·¸ ê¸€ ì‘ì„±

        Args:
            selected_topic: ì„ íƒëœ ì§ˆë¬¸í˜• ì£¼ì œ
            trend_summary: ë‰´ìŠ¤ íë¦„ ìš”ì•½
            category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„

        Returns:
            ë¸”ë¡œê·¸ ê¸€ ë°ì´í„° (title, content, tags ë“±)
        """
        prompt = QUESTION_BASED_ARTICLE_PROMPT.format(
            selected_topic=selected_topic,
            trend_summary=trend_summary,
            category_name=category_name,
        )

        response = self.model.generate_content(prompt)
        article = self._parse_json_response(response.text)

        article["article_type"] = "question_based"
        article["source_topic"] = selected_topic

        return article

    def generate_from_news_flow(self, news_data: dict, topic_index: int = 0) -> dict:
        """ë‰´ìŠ¤ íë¦„ ê¸°ë°˜ ì§ˆë¬¸í˜• ê¸€ ìƒì„± (í†µí•© ë©”ì„œë“œ)

        Args:
            news_data: collect_news_titles()ì˜ ë°˜í™˜ê°’
            topic_index: ì œì•ˆëœ ì£¼ì œ ì¤‘ ì„ íƒí•  ì¸ë±ìŠ¤ (0, 1, 2)

        Returns:
            ìƒì„±ëœ ë¸”ë¡œê·¸ ê¸€ ë°ì´í„°
        """
        # Step 1: ì£¼ì œ ì œì•ˆ ë°›ê¸°
        print("ğŸ“° ë‰´ìŠ¤ íë¦„ ë¶„ì„ ì¤‘...")
        topic_result = self.suggest_topics(news_data["titles"])

        print(f"ğŸ“Š íŠ¸ë Œë“œ: {topic_result['trend_summary']}")
        print(f"ğŸ‘€ ë…ì ê´€ì : {topic_result['reader_perspective']}")
        print("\nğŸ’¡ ì œì•ˆëœ ì£¼ì œ:")
        for i, t in enumerate(topic_result["suggested_topics"]):
            print(f"  {i+1}. [{t['target']}] {t['topic']}")

        # Step 2: ì£¼ì œ ì„ íƒ ë° ê¸€ ì‘ì„±
        selected = topic_result["suggested_topics"][topic_index]
        print(f"\nâœï¸ ì„ íƒëœ ì£¼ì œ: {selected['topic']}")
        print("ğŸ“ ê¸€ ìƒì„± ì¤‘...")

        article = self.generate_question_based_article(
            selected_topic=selected["topic"],
            trend_summary=topic_result["trend_summary"],
            category_name=news_data["category_name"],
        )

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        article["topic_data"] = topic_result
        article["selected_topic_index"] = topic_index

        return article

    # ============================================================
    # í†µí•© ë©”ì„œë“œ (1íšŒ API í˜¸ì¶œ + ìºì‹±)
    # ============================================================

    def generate_unified_article(self, news_data: dict, use_cache: bool = True) -> dict:
        """ë‰´ìŠ¤ íë¦„ ë¶„ì„ + ê¸€ ì‘ì„±ì„ 1íšŒ API í˜¸ì¶œë¡œ ì²˜ë¦¬

        Args:
            news_data: collect_news_titles()ì˜ ë°˜í™˜ê°’
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)

        Returns:
            ìƒì„±ëœ ë¸”ë¡œê·¸ ê¸€ ë°ì´í„°
        """
        category = news_data.get("category", "ai")
        category_name = news_data.get("category_name", "AI/í…Œí¬")
        titles = news_data.get("titles", [])

        # ìºì‹œ í™•ì¸
        if use_cache:
            cache_key = self._get_cache_key(titles, category)
            cached = self._get_cached_article(cache_key)
            if cached:
                return cached

        # ë‰´ìŠ¤ ì œëª©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        titles_str = "\n".join([f"- {item['title']}" for item in titles])

        # í†µí•© í”„ë¡¬í”„íŠ¸ë¡œ 1íšŒ API í˜¸ì¶œ
        print("ğŸ“° ë‰´ìŠ¤ ë¶„ì„ ë° ê¸€ ìƒì„± ì¤‘... (1íšŒ API í˜¸ì¶œ)")
        prompt = UNIFIED_ARTICLE_PROMPT.format(
            news_titles=titles_str,
            category_name=category_name,
        )

        response = self.model.generate_content(prompt)
        article = self._parse_json_response(response.text)

        # ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ“Š íŠ¸ë Œë“œ: {article.get('trend_summary', '')}")
        print(f"ğŸ‘€ ë…ì ê´€ì : {article.get('reader_perspective', '')}")
        print(f"ğŸ’¡ ì„ ì •ëœ ì£¼ì œ: {article.get('selected_topic', '')}")
        print(f"âœï¸ ì œëª©: {article.get('title', '')}")

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        article["article_type"] = "unified"
        article["source_topic"] = article.get("selected_topic", "")

        # ìºì‹œ ì €ì¥
        if use_cache:
            self._save_to_cache(cache_key, article)
            print("ğŸ’¾ ìºì‹œì— ì €ì¥ë¨")

        return article


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    from src.news_collector import NewsCollector

    collector = NewsCollector()
    generator = ContentGenerator()

    print("=" * 50)
    print("ì§ˆë¬¸í˜• ì½˜í…ì¸  ìƒì„± í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ë°©ì‹)")
    print("=" * 50)

    # Step 1: ë‰´ìŠ¤ ì œëª© ìˆ˜ì§‘
    news_data = collector.collect_news_titles("ai")
    print(f"\nìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì œëª© ìˆ˜: {len(news_data['titles'])}")

    # Step 2: ì£¼ì œ ì œì•ˆ + ê¸€ ìƒì„±
    article = generator.generate_from_news_flow(news_data, topic_index=0)

    print(f"\n{'=' * 50}")
    print("=== ìƒì„±ëœ ê¸€ ===")
    print(f"{'=' * 50}")
    print(f"ì œëª©: {article['title']}")
    print(f"ë©”íƒ€: {article['meta_description']}")
    print(f"íƒœê·¸: {', '.join(article['tags'])}")
    print(f"\në³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\n{article['content'][:800]}...")
